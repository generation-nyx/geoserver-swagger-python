# coding: utf-8

"""
    GeoServer Data Stores

    A data store contains vector format spatial data. It can be a file (such as a shapefile), a database (such as PostGIS), or a server (such as a remote Web Feature Service).  # noqa: E501

    OpenAPI spec version: 1.0.0
    Contact: geoserver-users@sourceforge.net
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


from __future__ import absolute_import

import re  # noqa: F401

# python 2 and python 3 compatibility library
import six

from swagger_client.api_client import ApiClient


class DataStoresApi(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient()
        self.api_client = api_client

    def clean_all_mongo_schemas(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Cleans all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501

        Cleans all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.clean_all_mongo_schemas(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.clean_all_mongo_schemas_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.clean_all_mongo_schemas_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def clean_all_mongo_schemas_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Cleans all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501

        Cleans all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.clean_all_mongo_schemas_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method clean_all_mongo_schemas" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `clean_all_mongo_schemas`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `clean_all_mongo_schemas`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['text/plain'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/appschemastores/{storeName}/cleanSchemas', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def clean_mongo_schema(self, workspace_name, store_name, internal_store_id, **kwargs):  # noqa: E501
        """Cleans a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501

        Cleans a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.clean_mongo_schema(workspace_name, store_name, internal_store_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str internal_store_id: The store ID for the internal MongoDB store as specified on App-Schema Mappings. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.clean_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, **kwargs)  # noqa: E501
        else:
            (data) = self.clean_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, **kwargs)  # noqa: E501
            return data

    def clean_mongo_schema_with_http_info(self, workspace_name, store_name, internal_store_id, **kwargs):  # noqa: E501
        """Cleans a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501

        Cleans a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.clean_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str internal_store_id: The store ID for the internal MongoDB store as specified on App-Schema Mappings. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'internal_store_id']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method clean_mongo_schema" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `clean_mongo_schema`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `clean_mongo_schema`")  # noqa: E501
        # verify the required parameter 'internal_store_id' is set
        if self.api_client.client_side_validation and ('internal_store_id' not in params or
                                                       params['internal_store_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `internal_store_id` when calling `clean_mongo_schema`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501
        if 'internal_store_id' in params:
            path_params['internalStoreId'] = params['internal_store_id']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['text/plain'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/appschemastores/{storeName}/datastores/{internalStoreId}/cleanSchemas', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def delete_data_store_upload(self, **kwargs):  # noqa: E501
        """delete_data_store_upload  # noqa: E501

        Invalid, only used for uploads  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_data_store_upload(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.delete_data_store_upload_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.delete_data_store_upload_with_http_info(**kwargs)  # noqa: E501
            return data

    def delete_data_store_upload_with_http_info(self, **kwargs):  # noqa: E501
        """delete_data_store_upload  # noqa: E501

        Invalid, only used for uploads  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_data_store_upload_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method delete_data_store_upload" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/{method}.{format}', 'DELETE',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def delete_datastore(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Delete data store  # noqa: E501

        Deletes a data store from the server.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_datastore(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to delete. (required)
        :param bool recurse: The recurse controls recursive deletion. When set to true all resources contained in the store are also removed. The default value is \"false\".
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.delete_datastore_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.delete_datastore_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def delete_datastore_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Delete data store  # noqa: E501

        Deletes a data store from the server.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_datastore_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to delete. (required)
        :param bool recurse: The recurse controls recursive deletion. When set to true all resources contained in the store are also removed. The default value is \"false\".
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'recurse']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method delete_datastore" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `delete_datastore`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `delete_datastore`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []
        if 'recurse' in params:
            query_params.append(('recurse', params['recurse']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'DELETE',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def deletedatastores(self, **kwargs):  # noqa: E501
        """deletedatastores  # noqa: E501

        Invalid. Use /datastores/{datastore} instead.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.deletedatastores(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.deletedatastores_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.deletedatastores_with_http_info(**kwargs)  # noqa: E501
            return data

    def deletedatastores_with_http_info(self, **kwargs):  # noqa: E501
        """deletedatastores  # noqa: E501

        Invalid. Use /datastores/{datastore} instead.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.deletedatastores_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method deletedatastores" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'DELETE',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def get_data_store(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Retrieve a particular data store from a workspace  # noqa: E501

        Controls a particular data store in a given workspace. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores/{datastore}.xml\" for XML).  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool quiet_on_not_found: The quietOnNotFound parameter avoids logging an exception when the data store is not present. Note that 404 status code will still be returned.
        :return: Datastore
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.get_data_store_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.get_data_store_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def get_data_store_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Retrieve a particular data store from a workspace  # noqa: E501

        Controls a particular data store in a given workspace. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores/{datastore}.xml\" for XML).  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool quiet_on_not_found: The quietOnNotFound parameter avoids logging an exception when the data store is not present. Note that 404 status code will still be returned.
        :return: Datastore
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'quiet_on_not_found']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_data_store" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `get_data_store`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `get_data_store`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []
        if 'quiet_on_not_found' in params:
            query_params.append(('quietOnNotFound', params['quiet_on_not_found']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/xml', 'application/json', 'text/html'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='Datastore',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def get_data_store_upload(self, workspace_name, store_name, method, format, **kwargs):  # noqa: E501
        """get_data_store_upload  # noqa: E501

        Deprecated. Retrieve the underlying files for the data store as a zip file with MIME type application/zip  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store_upload(workspace_name, store_name, method, format, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the store to be retrieved (required)
        :param str method: The upload method. Can be \"url\", \"file\", \"external\". Unused for GET (required)
        :param str format: The type of source data store (e.g., \"shp\"). Unused for GET (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.get_data_store_upload_with_http_info(workspace_name, store_name, method, format, **kwargs)  # noqa: E501
        else:
            (data) = self.get_data_store_upload_with_http_info(workspace_name, store_name, method, format, **kwargs)  # noqa: E501
            return data

    def get_data_store_upload_with_http_info(self, workspace_name, store_name, method, format, **kwargs):  # noqa: E501
        """get_data_store_upload  # noqa: E501

        Deprecated. Retrieve the underlying files for the data store as a zip file with MIME type application/zip  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store_upload_with_http_info(workspace_name, store_name, method, format, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the store to be retrieved (required)
        :param str method: The upload method. Can be \"url\", \"file\", \"external\". Unused for GET (required)
        :param str format: The type of source data store (e.g., \"shp\"). Unused for GET (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'method', 'format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_data_store_upload" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `get_data_store_upload`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `get_data_store_upload`")  # noqa: E501
        # verify the required parameter 'method' is set
        if self.api_client.client_side_validation and ('method' not in params or
                                                       params['method'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `method` when calling `get_data_store_upload`")  # noqa: E501
        # verify the required parameter 'format' is set
        if self.api_client.client_side_validation and ('format' not in params or
                                                       params['format'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `format` when calling `get_data_store_upload`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501
        if 'method' in params:
            path_params['method'] = params['method']  # noqa: E501
        if 'format' in params:
            path_params['format'] = params['format']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/{method}.{format}', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def get_datastores(self, workspace_name, **kwargs):  # noqa: E501
        """Get a list of data stores  # noqa: E501

        List all data stores in workspace ws. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores.xml\" for XML)  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_datastores(workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :return: DataStoreResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.get_datastores_with_http_info(workspace_name, **kwargs)  # noqa: E501
        else:
            (data) = self.get_datastores_with_http_info(workspace_name, **kwargs)  # noqa: E501
            return data

    def get_datastores_with_http_info(self, workspace_name, **kwargs):  # noqa: E501
        """Get a list of data stores  # noqa: E501

        List all data stores in workspace ws. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores.xml\" for XML)  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_datastores_with_http_info(workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :return: DataStoreResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_datastores" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `get_datastores`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/xml', 'application/json', 'text/html'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='DataStoreResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def post_data_store_reset(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Reset the caches related to this specific data store.  # noqa: E501

        Resets caches for this data store. This operation is used to force GeoServer to drop caches associated to this data store, and reconnect to the vector source the next time it is needed by a request. This is useful as the store can keep state, such as a connection pool, and the structure of the feature types it's serving.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_data_store_reset(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.post_data_store_reset_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.post_data_store_reset_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def post_data_store_reset_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Reset the caches related to this specific data store.  # noqa: E501

        Resets caches for this data store. This operation is used to force GeoServer to drop caches associated to this data store, and reconnect to the vector source the next time it is needed by a request. This is useful as the store can keep state, such as a connection pool, and the structure of the feature types it's serving.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_data_store_reset_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method post_data_store_reset" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `post_data_store_reset`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `post_data_store_reset`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/reset', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def post_data_store_upload(self, **kwargs):  # noqa: E501
        """post_data_store_upload  # noqa: E501

        Invalid, use PUT for uploads  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_data_store_upload(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.post_data_store_upload_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.post_data_store_upload_with_http_info(**kwargs)  # noqa: E501
            return data

    def post_data_store_upload_with_http_info(self, **kwargs):  # noqa: E501
        """post_data_store_upload  # noqa: E501

        Invalid, use PUT for uploads  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_data_store_upload_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method post_data_store_upload" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/{method}.{format}', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def post_datastore(self, **kwargs):  # noqa: E501
        """post_datastore  # noqa: E501

        Invalid. Use PUT to edit a data store definition, or POST with /datastore to add a new definition.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_datastore(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.post_datastore_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.post_datastore_with_http_info(**kwargs)  # noqa: E501
            return data

    def post_datastore_with_http_info(self, **kwargs):  # noqa: E501
        """post_datastore  # noqa: E501

        Invalid. Use PUT to edit a data store definition, or POST with /datastore to add a new definition.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_datastore_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method post_datastore" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def post_datastores(self, workspace_name, data_store_body, **kwargs):  # noqa: E501
        """Create a new data store  # noqa: E501

        Adds a new data store to the workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_datastores(workspace_name, data_store_body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param Datastore data_store_body: The data store body information to upload.  The contents of the connection parameters will differ depending on the type of data store being added.  - GeoPackage    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <database>file:///path/to/nyc.gpkg</database>         <dbtype>geopkg</dbtype>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"database\",\"$\":\"file:///path/to/nyc.gpkg\"},             {\"@key\":\"dbtype\",\"$\":\"geopkg\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | database | Database | user | File | True | ` ` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | namespace | Namespace prefix | user | String | False | ` ` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | dbtype | Type | program | String | True | `geopkg` |   | passwd | password used to login | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | user | user name to login as | user | String | False | ` ` |  - PostGIS    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <host>localhost</host>         <port>5432</port>         <database>nyc</database>         <user>bob</user>         <passwd>postgres</passwd>         <dbtype>postgis</dbtype>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"host\",\"$\":\"localhost\"},             {\"@key\":\"port\",\"$\":\"5432\"},             {\"@key\":\"database\",\"$\":\"nyc\"},             {\"@key\":\"user\",\"$\":\"bob\"},             {\"@key\":\"passwd\",\"$\":\"postgres\"},             {\"@key\":\"dbtype\",\"$\":\"postgis\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | port | Port | user | Integer | True | `5432` |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |   | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |   | create database params | Extra specifications appended to the CREATE DATABASE command | advanced | String | False | `` |   | dbtype | Type | program | String | True | `postgis` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | namespace | Namespace prefix | user | String | False | ` ` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | passwd | password used to login | user | String | False | ` ` |   | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows us to push more of the filter into the database, increasing performance of the postgis table. | advanced | Boolean | False | `False` |   | host | Host | user | String | True | `localhost` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |   | database | Database | user | String | False | ` ` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | preparedStatements | Use prepared statements | user | Boolean | False | `False` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | schema | Schema | user | String | False | `public` |   | user | user name to login as | user | String | True | ` ` |  - Shapefile    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <url>file:/path/to/nyc.shp</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/nyc.shp\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |  - Directory of spatial files (shapefiles)    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <url>file:/path/to/directory</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/directory\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |   - Web Feature Service    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <GET_CAPABILITIES_URL>http://localhost:8080/geoserver/wfs?request=GetCapabilities</GET_CAPABILITIES_URL>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"GET_CAPABILITIES_URL\",\"$\":\"http://localhost:8080/geoserver/wfs?request=GetCapabilities\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |   | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |   | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |   | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |   | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |   | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |   | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |   | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |   | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |   | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |   | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |   | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |   | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |   | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |   | Maximum features | Positive integer used as a hard limit for the number of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |   | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |   | WFS Strategy | Override WFS strategy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |   | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |   | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |   | Outputformat | This allows the user to specify an output format, different from the default one. | advanced | String | False | ` ` |  (required)
        :return: str
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.post_datastores_with_http_info(workspace_name, data_store_body, **kwargs)  # noqa: E501
        else:
            (data) = self.post_datastores_with_http_info(workspace_name, data_store_body, **kwargs)  # noqa: E501
            return data

    def post_datastores_with_http_info(self, workspace_name, data_store_body, **kwargs):  # noqa: E501
        """Create a new data store  # noqa: E501

        Adds a new data store to the workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.post_datastores_with_http_info(workspace_name, data_store_body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param Datastore data_store_body: The data store body information to upload.  The contents of the connection parameters will differ depending on the type of data store being added.  - GeoPackage    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <database>file:///path/to/nyc.gpkg</database>         <dbtype>geopkg</dbtype>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"database\",\"$\":\"file:///path/to/nyc.gpkg\"},             {\"@key\":\"dbtype\",\"$\":\"geopkg\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | database | Database | user | File | True | ` ` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | namespace | Namespace prefix | user | String | False | ` ` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | dbtype | Type | program | String | True | `geopkg` |   | passwd | password used to login | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | user | user name to login as | user | String | False | ` ` |  - PostGIS    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <host>localhost</host>         <port>5432</port>         <database>nyc</database>         <user>bob</user>         <passwd>postgres</passwd>         <dbtype>postgis</dbtype>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"host\",\"$\":\"localhost\"},             {\"@key\":\"port\",\"$\":\"5432\"},             {\"@key\":\"database\",\"$\":\"nyc\"},             {\"@key\":\"user\",\"$\":\"bob\"},             {\"@key\":\"passwd\",\"$\":\"postgres\"},             {\"@key\":\"dbtype\",\"$\":\"postgis\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | port | Port | user | Integer | True | `5432` |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |   | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |   | create database params | Extra specifications appended to the CREATE DATABASE command | advanced | String | False | `` |   | dbtype | Type | program | String | True | `postgis` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | namespace | Namespace prefix | user | String | False | ` ` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | passwd | password used to login | user | String | False | ` ` |   | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows us to push more of the filter into the database, increasing performance of the postgis table. | advanced | Boolean | False | `False` |   | host | Host | user | String | True | `localhost` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |   | database | Database | user | String | False | ` ` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | preparedStatements | Use prepared statements | user | Boolean | False | `False` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | schema | Schema | user | String | False | `public` |   | user | user name to login as | user | String | True | ` ` |  - Shapefile    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <url>file:/path/to/nyc.shp</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/nyc.shp\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |  - Directory of spatial files (shapefiles)    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <url>file:/path/to/directory</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/directory\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |   - Web Feature Service    Examples:   - application/xml:      ```     <dataStore>       <name>nyc</name>       <connectionParameters>         <GET_CAPABILITIES_URL>http://localhost:8080/geoserver/wfs?request=GetCapabilities</GET_CAPABILITIES_URL>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"name\": \"nyc\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"GET_CAPABILITIES_URL\",\"$\":\"http://localhost:8080/geoserver/wfs?request=GetCapabilities\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |   | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |   | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |   | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |   | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |   | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |   | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |   | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |   | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |   | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |   | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |   | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |   | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |   | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |   | Maximum features | Positive integer used as a hard limit for the number of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |   | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |   | WFS Strategy | Override WFS strategy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |   | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |   | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |   | Outputformat | This allows the user to specify an output format, different from the default one. | advanced | String | False | ` ` |  (required)
        :return: str
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'data_store_body']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method post_datastores" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `post_datastores`")  # noqa: E501
        # verify the required parameter 'data_store_body' is set
        if self.api_client.client_side_validation and ('data_store_body' not in params or
                                                       params['data_store_body'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `data_store_body` when calling `post_datastores`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'data_store_body' in params:
            body_params = params['data_store_body']
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/xml', 'application/json', 'text/html'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/xml', 'application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='str',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def put_data_store_reset(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Reset the caches related to this specific data store.  # noqa: E501

        Resets caches for this data store. This operation is used to force GeoServer to drop caches associated to this data store, and reconnect to the vector source the next time it is needed by a request. This is useful as the store can keep state, such as a connection pool, and the structure of the feature types it's serving.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_data_store_reset(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.put_data_store_reset_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.put_data_store_reset_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def put_data_store_reset_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Reset the caches related to this specific data store.  # noqa: E501

        Resets caches for this data store. This operation is used to force GeoServer to drop caches associated to this data store, and reconnect to the vector source the next time it is needed by a request. This is useful as the store can keep state, such as a connection pool, and the structure of the feature types it's serving.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_data_store_reset_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method put_data_store_reset" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `put_data_store_reset`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `put_data_store_reset`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/reset', 'PUT',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def put_data_store_upload(self, workspace_name, store_name, method, format, **kwargs):  # noqa: E501
        """Uploads files to the data store, creating it if necessary  # noqa: E501

        Creates or modifies a single data store by uploading spatial data or mapping configuration (in case an app-schema data store is targeted) files.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_data_store_upload(workspace_name, store_name, method, format, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the coverage stores. (required)
        :param str store_name: The name of the store to be retrieved (required)
        :param str method: The upload method. Can be \"url\", \"file\", \"external\". \"file\" uploads a file from a local source. The body of the request is the file itself. \"url\" uploads a file from an remote source. The body of the request is a URL pointing to the file to upload. This URL must be visible from the server. \"external\" uses an existing file on the server. The body of the request is the absolute path to the existing file. (required)
        :param str format: The type of source data store (e.g., \"shp\"). (required)
        :param str configure: The configure parameter controls if a coverage/layer are configured upon file upload, in addition to creating the store. It can have a value of \"none\" to avoid configuring coverages.
        :param str target: The type of target data store (e.g., \"shp\"). Same as format if not provided.
        :param str update: The update mode. If \"overwrite\", will overwrite existing data. Otherwise, will append to existing data.
        :param str charset: The character set of the data.
        :param str filename: The filename parameter specifies the target file name for the file to be uploaded. This is important to avoid clashes with existing files.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.put_data_store_upload_with_http_info(workspace_name, store_name, method, format, **kwargs)  # noqa: E501
        else:
            (data) = self.put_data_store_upload_with_http_info(workspace_name, store_name, method, format, **kwargs)  # noqa: E501
            return data

    def put_data_store_upload_with_http_info(self, workspace_name, store_name, method, format, **kwargs):  # noqa: E501
        """Uploads files to the data store, creating it if necessary  # noqa: E501

        Creates or modifies a single data store by uploading spatial data or mapping configuration (in case an app-schema data store is targeted) files.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_data_store_upload_with_http_info(workspace_name, store_name, method, format, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the coverage stores. (required)
        :param str store_name: The name of the store to be retrieved (required)
        :param str method: The upload method. Can be \"url\", \"file\", \"external\". \"file\" uploads a file from a local source. The body of the request is the file itself. \"url\" uploads a file from an remote source. The body of the request is a URL pointing to the file to upload. This URL must be visible from the server. \"external\" uses an existing file on the server. The body of the request is the absolute path to the existing file. (required)
        :param str format: The type of source data store (e.g., \"shp\"). (required)
        :param str configure: The configure parameter controls if a coverage/layer are configured upon file upload, in addition to creating the store. It can have a value of \"none\" to avoid configuring coverages.
        :param str target: The type of target data store (e.g., \"shp\"). Same as format if not provided.
        :param str update: The update mode. If \"overwrite\", will overwrite existing data. Otherwise, will append to existing data.
        :param str charset: The character set of the data.
        :param str filename: The filename parameter specifies the target file name for the file to be uploaded. This is important to avoid clashes with existing files.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'method', 'format', 'configure', 'target', 'update', 'charset', 'filename']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method put_data_store_upload" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `put_data_store_upload`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `put_data_store_upload`")  # noqa: E501
        # verify the required parameter 'method' is set
        if self.api_client.client_side_validation and ('method' not in params or
                                                       params['method'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `method` when calling `put_data_store_upload`")  # noqa: E501
        # verify the required parameter 'format' is set
        if self.api_client.client_side_validation and ('format' not in params or
                                                       params['format'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `format` when calling `put_data_store_upload`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501
        if 'method' in params:
            path_params['method'] = params['method']  # noqa: E501
        if 'format' in params:
            path_params['format'] = params['format']  # noqa: E501

        query_params = []
        if 'configure' in params:
            query_params.append(('configure', params['configure']))  # noqa: E501
        if 'target' in params:
            query_params.append(('target', params['target']))  # noqa: E501
        if 'update' in params:
            query_params.append(('update', params['update']))  # noqa: E501
        if 'charset' in params:
            query_params.append(('charset', params['charset']))  # noqa: E501
        if 'filename' in params:
            query_params.append(('filename', params['filename']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}/{method}.{format}', 'PUT',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def put_datastore(self, workspace_name, store_name, data_store_body, **kwargs):  # noqa: E501
        """Modify a data store.  # noqa: E501

        Modify data store ds. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores/{ds}.xml\" for XML).  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_datastore(workspace_name, store_name, data_store_body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :param Datastore data_store_body: The updated data store definition. For a PUT, only values which should be changed need to be included. The connectionParameters map counts as a single value,  so if you change it all pre-existing connection parameters will be overwritten.  The contents of the connection parameters will differ depending on the type of data store being added.  - GeoPackage    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <database>file:///path/to/nyc.gpkg</database>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"database\",\"$\":\"file:///path/to/nyc.gpkg\"},           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | database | Database | user | File | True | ` ` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | namespace | Namespace prefix | user | String | False | ` ` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | dbtype | Type | program | String | True | `geopkg` |   | passwd | password used to login | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | user | user name to login as | user | String | False | ` ` |  - PostGIS    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <host>localhost</host>         <port>5432</port>         <database>nyc</database>         <user>bob</user>         <passwd>postgres</passwd>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"host\",\"$\":\"localhost\"},             {\"@key\":\"port\",\"$\":\"5432\"},             {\"@key\":\"database\",\"$\":\"nyc\"},             {\"@key\":\"user\",\"$\":\"bob\"},             {\"@key\":\"passwd\",\"$\":\"postgres\"},           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | port | Port | user | Integer | True | `5432` |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |   | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |   | create database params | Extra specifications appended to the CREATE DATABASE command | advanced | String | False | `` |   | dbtype | Type | program | String | True | `postgis` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | namespace | Namespace prefix | user | String | False | ` ` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | passwd | password used to login | user | String | False | ` ` |   | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows us to push more of the filter into the database, increasing performance of the postgis table. | advanced | Boolean | False | `False` |   | host | Host | user | String | True | `localhost` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |   | database | Database | user | String | False | ` ` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | preparedStatements | Use prepared statements | user | Boolean | False | `False` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | schema | Schema | user | String | False | `public` |   | user | user name to login as | user | String | True | ` ` |  - Shapefile    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <url>file:/path/to/nyc.shp</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/nyc.shp\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |  - Directory of spatial files (shapefiles)    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <url>file:/path/to/directory</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/directory\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |   - Web Feature Service    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <GET_CAPABILITIES_URL>http://localhost:8080/geoserver/wfs?request=GetCapabilities</GET_CAPABILITIES_URL>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"GET_CAPABILITIES_URL\",\"$\":\"http://localhost:8080/geoserver/wfs?request=GetCapabilities\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |   | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |   | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |   | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |   | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |   | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |   | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |   | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |   | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |   | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |   | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |   | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |   | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |   | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |   | Maximum features | Positive integer used as a hard limit for the number of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |   | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |   | WFS Strategy | Override WFS strategy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |   | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |   | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |   | Outputformat | This allows the user to specify an output format, different from the default one. | advanced | String | False | ` ` |  (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.put_datastore_with_http_info(workspace_name, store_name, data_store_body, **kwargs)  # noqa: E501
        else:
            (data) = self.put_datastore_with_http_info(workspace_name, store_name, data_store_body, **kwargs)  # noqa: E501
            return data

    def put_datastore_with_http_info(self, workspace_name, store_name, data_store_body, **kwargs):  # noqa: E501
        """Modify a data store.  # noqa: E501

        Modify data store ds. Use the \"Accept:\" header to specify format or append an extension to the endpoint (example \"/datastores/{ds}.xml\" for XML).  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.put_datastore_with_http_info(workspace_name, store_name, data_store_body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data store. (required)
        :param str store_name: The name of the data store to modify. (required)
        :param Datastore data_store_body: The updated data store definition. For a PUT, only values which should be changed need to be included. The connectionParameters map counts as a single value,  so if you change it all pre-existing connection parameters will be overwritten.  The contents of the connection parameters will differ depending on the type of data store being added.  - GeoPackage    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <database>file:///path/to/nyc.gpkg</database>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"database\",\"$\":\"file:///path/to/nyc.gpkg\"},           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | database | Database | user | File | True | ` ` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | namespace | Namespace prefix | user | String | False | ` ` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | dbtype | Type | program | String | True | `geopkg` |   | passwd | password used to login | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | user | user name to login as | user | String | False | ` ` |  - PostGIS    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <host>localhost</host>         <port>5432</port>         <database>nyc</database>         <user>bob</user>         <passwd>postgres</passwd>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"host\",\"$\":\"localhost\"},             {\"@key\":\"port\",\"$\":\"5432\"},             {\"@key\":\"database\",\"$\":\"nyc\"},             {\"@key\":\"user\",\"$\":\"bob\"},             {\"@key\":\"passwd\",\"$\":\"postgres\"},           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |   | validate connections | check connection is alive before using it | user | Boolean | False | `True` |   | port | Port | user | Integer | True | `5432` |   | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |   | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |   | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |   | create database params | Extra specifications appended to the CREATE DATABASE command | advanced | String | False | `` |   | dbtype | Type | program | String | True | `postgis` |   | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |   | namespace | Namespace prefix | user | String | False | ` ` |   | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |   | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |   | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |   | min connections | minimum number of pooled connections | user | Integer | False | `1` |   | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |   | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |   | passwd | password used to login | user | String | False | ` ` |   | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows us to push more of the filter into the database, increasing performance of the postgis table. | advanced | Boolean | False | `False` |   | host | Host | user | String | True | `localhost` |   | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |   | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |   | Evictor run periodicity | number of seconds between idle object evictor runs (default, 300 seconds) | user | Integer | False | `300` |   | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |   | database | Database | user | String | False | ` ` |   | fetch size | number of records read with each interaction with the DBMS | user | Integer | False | `1000` |   | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |   | max connections | maximum number of open connections | user | Integer | False | `10` |   | preparedStatements | Use prepared statements | user | Boolean | False | `False` |   | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |   | schema | Schema | user | String | False | `public` |   | user | user name to login as | user | String | True | ` ` |  - Shapefile    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <url>file:/path/to/nyc.shp</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/nyc.shp\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |  - Directory of spatial files (shapefiles)    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <url>file:/path/to/directory</url>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"url\",\"$\":\"file:/path/to/directory\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |   | namespace | URI to the namespace | advanced | URI | False | ` ` |   | filetype | Discriminator for directory stores | program | String | False | `shapefile` |   | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |   | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |   | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |   | url | url to a .shp file | user | URL | True | ` ` |   | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |   | memory mapped buffer | enable/disable the use of memory-mapped IO | advanced | Boolean | False | `False` |   | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |   - Web Feature Service    Examples:   - application/xml:      ```     <dataStore>       <description>A data store</description>       <enabled>true</enabled>       <__default>true</__default>       <connectionParameters>         <GET_CAPABILITIES_URL>http://localhost:8080/geoserver/wfs?request=GetCapabilities</GET_CAPABILITIES_URL>       </connectionParameters>     </dataStore>     ```    - application/json:      ```     {       \"dataStore\": {         \"description\": \"A data store\",         \"enabled\": \"true\",         \"_default\": \"true\",         \"connectionParameters\": {           \"entry\": [             {\"@key\":\"GET_CAPABILITIES_URL\",\"$\":\"http://localhost:8080/geoserver/wfs?request=GetCapabilities\"}           ]         }       }     }     ```    Connection Parameters:    | key | description | level | type | required | default |   | --- | ----------- | ----- | ---- | -------- | ------- |   | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |   | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |   | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |   | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |   | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |   | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |   | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |   | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |   | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |   | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |   | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |   | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |   | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |   | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |   | Maximum features | Positive integer used as a hard limit for the number of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |   | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |   | WFS Strategy | Override WFS strategy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |   | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |   | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |   | Outputformat | This allows the user to specify an output format, different from the default one. | advanced | String | False | ` ` |  (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'data_store_body']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method put_datastore" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `put_datastore`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `put_datastore`")  # noqa: E501
        # verify the required parameter 'data_store_body' is set
        if self.api_client.client_side_validation and ('data_store_body' not in params or
                                                       params['data_store_body'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `data_store_body` when calling `put_datastore`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'data_store_body' in params:
            body_params = params['data_store_body']
        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/xml', 'application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'PUT',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def putdatastores(self, **kwargs):  # noqa: E501
        """putdatastores  # noqa: E501

        Invalid. Use POST for adding a new data store, or PUT on /datastores/{datastore} to edit an existing data store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.putdatastores(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.putdatastores_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.putdatastores_with_http_info(**kwargs)  # noqa: E501
            return data

    def putdatastores_with_http_info(self, **kwargs):  # noqa: E501
        """putdatastores  # noqa: E501

        Invalid. Use POST for adding a new data store, or PUT on /datastores/{datastore} to edit an existing data store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.putdatastores_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method putdatastores" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'PUT',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def rebuild_all_mongo_schemas(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Rebuilds all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501

        Rebuilds all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.rebuild_all_mongo_schemas(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str ids: Comma separated MongoDB object IDs for use in new generated schema.
        :param int max: Max number of objects for use in new generated schema.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.rebuild_all_mongo_schemas_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.rebuild_all_mongo_schemas_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def rebuild_all_mongo_schemas_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Rebuilds all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501

        Rebuilds all MongoDB internal stores Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.rebuild_all_mongo_schemas_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str ids: Comma separated MongoDB object IDs for use in new generated schema.
        :param int max: Max number of objects for use in new generated schema.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'ids', 'max']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method rebuild_all_mongo_schemas" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `rebuild_all_mongo_schemas`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `rebuild_all_mongo_schemas`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []
        if 'ids' in params:
            query_params.append(('ids', params['ids']))  # noqa: E501
        if 'max' in params:
            query_params.append(('max', params['max']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['text/plain'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/appschemastores/{storeName}/rebuildMongoSchemas', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def rebuild_mongo_schema(self, workspace_name, store_name, internal_store_id, **kwargs):  # noqa: E501
        """Rebuilds a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501

        Rebuilds a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.rebuild_mongo_schema(workspace_name, store_name, internal_store_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str internal_store_id: The store ID for the internal MongoDB store as specified on App-Schema Mappings. (required)
        :param str ids: Comma separated MongoDB object IDs for use in new generated schema.
        :param int max: Max number of objects for use in new generated schema.
        :param str schema: Name of schema to re-build.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.rebuild_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, **kwargs)  # noqa: E501
        else:
            (data) = self.rebuild_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, **kwargs)  # noqa: E501
            return data

    def rebuild_mongo_schema_with_http_info(self, workspace_name, store_name, internal_store_id, **kwargs):  # noqa: E501
        """Rebuilds a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501

        Rebuilds a MongoDB internal store Schemas for an App-Schema store.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.rebuild_mongo_schema_with_http_info(workspace_name, store_name, internal_store_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the workspace containing the data stores. (required)
        :param str store_name: The name of the App-Schema store (required)
        :param str internal_store_id: The store ID for the internal MongoDB store as specified on App-Schema Mappings. (required)
        :param str ids: Comma separated MongoDB object IDs for use in new generated schema.
        :param int max: Max number of objects for use in new generated schema.
        :param str schema: Name of schema to re-build.
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'internal_store_id', 'ids', 'max', 'schema']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method rebuild_mongo_schema" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if self.api_client.client_side_validation and ('workspace_name' not in params or
                                                       params['workspace_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `workspace_name` when calling `rebuild_mongo_schema`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if self.api_client.client_side_validation and ('store_name' not in params or
                                                       params['store_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `store_name` when calling `rebuild_mongo_schema`")  # noqa: E501
        # verify the required parameter 'internal_store_id' is set
        if self.api_client.client_side_validation and ('internal_store_id' not in params or
                                                       params['internal_store_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `internal_store_id` when calling `rebuild_mongo_schema`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501
        if 'internal_store_id' in params:
            path_params['internalStoreId'] = params['internal_store_id']  # noqa: E501

        query_params = []
        if 'ids' in params:
            query_params.append(('ids', params['ids']))  # noqa: E501
        if 'max' in params:
            query_params.append(('max', params['max']))  # noqa: E501
        if 'schema' in params:
            query_params.append(('schema', params['schema']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['text/plain'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/appschemastores/{storeName}/datastores/{internalStoreId}/rebuildMongoSchemas', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)
